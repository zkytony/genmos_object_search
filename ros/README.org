* Example ROS package that uses genmos_object_search

Note that genmos_object_search is written in Python 3. For ROS, it is
best integrated with ROS Noetic.

** Setup

*** Create symbolic link

Go to the `src` folder of your ROS workspace. Then run:
#+begin_src
ln -s path/to/genmos_object_search/ros genmos_object_search_ros
#+end_src
This effectively adds a ROS package called "genmos_object_search_ros" into your workspace

*** Install Dependencies

This is a ROS package; Therefore, it is expected to operate within a ROS workspace.

Before building this package, make sure you have activated a virtualenv. Then, run
#+begin_src
source install_dependencies.bash
#+end_src
to install python dependencies.

*Note* that we use [[https://github.com/eric-wieser/ros_numpy][ros_numpy]] to convert point cloud ROS message to numpy array,
so that point cloud observation can be used to update the search region (see [[./src/genmos_ros/genmos_ros.py#117][code]]).
Typically, one installs ros_numpy by ~sudo apt-get install ros-noetic-ros-numpy~.
However, there are two issues (1) [[https://github.com/eric-wieser/ros_numpy/issues/37][this issue]] where numpy > 1.24 causes an AttributeError on `numpy.float`,
and that (2) the ros_numpy package was no longer maintained.

As a result, we folded the source code of ros_numpy into our repository,
under [[./thirdparty/ros_numpy]]. It is modified to be a standard Python
package that can be pip-installed. The installation is, still, handled
by ~source install_dependencies.bash~ so you do not need to do anything.


*** Build the ROS package
#+begin_src
catkin_make -DCATKIN_WHITELIST_PACKAGES="genmos_object_search_ros"
#+end_src

Note that if you are using the [robotdev Spot environment](https://github.com/zkytony/robotdev/tree/master/spot),
you need to run the following command instead
#+begin_src
build_spot -DCATKIN_WHITELIST_PACKAGES="genmos_object_search_ros"
#+end_src


*** Download Dataset and Models (Optional)
Install [[https://github.com/wkentaro/gdown][gdown]], then run download script:
#+begin_src
pip install gdown
python download.py
#+end_src
This will download both the ~SL\_OSM\_Dataset~ and the frame of reference
prediction models.  The ~SL\_OSM\_Dataset~ will be saved under ~data~, while the
models will be saved under ~models~.

Also, you will need to download spacy models. We use ~en_core_web_lg~ (400MB). To download it:
#+begin_src
python -m spacy download en_core_web_lg
#+end_src
